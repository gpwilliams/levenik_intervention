---
title: "Results"
author: "Glenn Williams"
date: "14<sup>th</sup> August, 2019 (Last updated: `r format(Sys.time(), '%d<sup>th</sup> %B, %Y')`)"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)

packages <- c(
  "tidyverse",
  "rlang",
  "here",
  "brms",
  "tidybayes",
  "bayestestR",
  "modelr",
  "ggforce",
  "ggrepel",
  "ggridges",
  "irr"
)

# load packages
lapply(packages, library, character.only = TRUE)

# load functions
r_function_list <- list.files(
  path = here("R", "00_functions"), 
  pattern = "R$",
  full.names = TRUE
)
purrr::walk(r_function_list, source)

# get citations
citations <- purrr::map(packages, citation)

# get file paths ----

# get model summaries only for easy loading
fitted_models_dir <- list.files(
  path = here("04_analysis", "01_models"),
  pattern = "rds$",
  full.names = TRUE
) %>% 
  str_subset("summary")
  

model_summaries_dir <- list.files(
  path = here("04_analysis", "02_summaries", "02_full-data"),
  pattern = "csv$",
  full.names = TRUE
)

plots_dir <- list.files(
  path = here("03_plots", "02_full-data"),
  pattern = "png$",
  full.names = TRUE
)

# load data ----

fitted_models <- purrr::map(fitted_models_dir, read_rds)

names(fitted_models) <- fitted_models_dir %>% 
  sub(".*/", "", .) %>% 
  substr(., 1, nchar(.)-4)
```

```{r define-renaming-variables}
summary_oldnames <- c(".value", "interval")
summary_newnames <- c("median", "percentile interval")
summary_drop <- c(".point", ".interval")
```

# Appendix A. Model Priors and Posterior Predictive Checks

Priors for the fitted models are described first by their expected distribution, and the parameters that define that distribution. For example, a prior of $\mathcal{N}(0, 1)$ describes a normal distribution with a mean of 0 and a standard deviation of 1. Similarly, a prior of $\mathcal{logistic}(0, 1)$ describes a logistic distribution with a mean of 0 and a standard deviation of 1. Note, by default, `brms` restricts priors on the *SD* to be positive.

Weakly informative regularising priors were used for all terms. All priors were centred on 0, with standard deviations ranging from 0.5 to 10, thus allowing for a range of values with less prior probability places on extreme responses. For the slope terms, the priors assume no effect to small effects for each parameter in either direction. Weakly informative regularising priors were also used for all standard deviation terms. Finally, an $LKJ(2)$ prior was used for the correlation between terms, which acts to down-weight perfect correlations (Vasishth et al., 2018). These priors are in some cases more informative than initially planned following our pre-registration (which used very weakly informative priors) to improve model fit (i.e. accounting for divergences during fitting). For example, the mu intercept and slope and gamma slope have standard deviations half as large as planned, while the standard deviation for the phi intercept is three times as large as planned. Additionally, 8000 iterations were used instead of 1000 and 6 chains were used rather than 4 chains to improve estimates in response to warnings about bulk and tail effective sample size, totalling 48,000 samples rather than the planned 4000.

The following priors were used for the exposure model:

- Intercept
  - $\mu$: $\mathcal{N}(0, 5)$
  - $\phi$: $\mathcal{N}(0, 3)$
  - $\alpha$: $\mathcal{logistic}(0, 1)$
  - $\gamma$: $\mathcal{logistic}(0, 1)$
- Slope
  - $\mu$: $\mathcal{N}(0, 0.5)$
  - $\phi$: $\mathcal{N}(0, 1)$
  - $\alpha$: $\mathcal{N}(0, 5)$
  - $\gamma$: $\mathcal{N}(0, 0.5)$
- *SD*
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 1)$
  - $\alpha$: $\mathcal{N}(0, 5)$
  - $\gamma$: $\mathcal{N}(0, 5)$
- *SD* by Participant Number
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 5)$
  - $\alpha$: $\mathcal{N}(0, 10)$
  - $\gamma$: $\mathcal{N}(0, 10)$
- *SD* by Item
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 5)$
  - $\alpha$: $\mathcal{N}(0, 10)$
  - $\gamma$: $\mathcal{N}(0, 10)$
- Correlation
  - $LKJ(2)$

For both testing models, the following priors were used:

- Intercept
  - $\mu$: $\mathcal{N}(0, 5)$
  - $\phi$: $\mathcal{N}(0, 3)$
  - $\alpha$: $\mathcal{logistic}(0, 1)$
  - $\gamma$: $\mathcal{logistic}(0, 1)$
- Slope
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 1)$
  - $\alpha$: $\mathcal{N}(0, 5)$
  - $\gamma$: $\mathcal{N}(0, 1)$
- *SD*
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 1)$
  - $\alpha$: $\mathcal{N}(0, 5)$
  - $\gamma$: $\mathcal{N}(0, 5)$
- *SD* by Participant Number
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 5)$
  - $\alpha$: $\mathcal{N}(0, 10)$
  - $\gamma$: $\mathcal{N}(0, 10)$
- *SD* by Item
  - $\mu$: $\mathcal{N}(0, 1)$
  - $\phi$: $\mathcal{N}(0, 5)$
  - $\alpha$: $\mathcal{N}(0, 10)$
  - $\gamma$: $\mathcal{N}(0, 10)$
- Correlation
  - $LKJ(2)$
  
Due to having more observations for analyses during the testing phase, both the $\mu$ and $\gamma$ slope terms use more weakly informative priors than the exposure model. This allows the data to have a larger impact on parameter estimates while having no impact on model convergence. 

Posterior predictive checks were performed for all three models, comparing the observed posterior density against samples from the fitted model. Well fitting models show concordance between observed and sampled posterior densities. Plots for each model are displayed below. Grey lines indicate samples from the posterior, while black lines indicate the observed sample density.

```{r pp-check-plots}
knitr::include_graphics(c(
  plots_dir[str_detect(plots_dir, "pp_check_exposure.png")],
  plots_dir[str_detect(plots_dir, "pp_check_testing.png")],
  plots_dir[str_detect(plots_dir, "pp_check_testing_cov.png")]
))
```

As can be seen from the plots, the posterior predictive checks indicate a generally good model fit in all instances, such that the model largely captures the shape of the data (i.e. especially capturing the 0 and 1 inflation in the testing model), but does not capture some discrepancies in the data which do not arise from any defined process (i.e. some larger densities in the testing model between the range of 0-1).
